{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e2908a-a2d3-42f5-9b99-b25007ef97dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 classes under /home/noushath/NSResearch/ASLR/data/RGB ArSL dataset\n",
      "Ain                       total= 244 | train= 170 val=  37 test=  37\n",
      "Al                        total= 276 | train= 194 val=  41 test=  41\n",
      "Alef                      total= 287 | train= 201 val=  43 test=  43\n",
      "Beh                       total= 307 | train= 215 val=  46 test=  46\n",
      "Dad                       total= 266 | train= 186 val=  40 test=  40\n",
      "Dal                       total= 235 | train= 165 val=  35 test=  35\n",
      "Feh                       total= 255 | train= 179 val=  38 test=  38\n",
      "Ghain                     total= 230 | train= 162 val=  34 test=  34\n",
      "Hah                       total= 246 | train= 172 val=  37 test=  37\n",
      "Heh                       total= 253 | train= 177 val=  38 test=  38\n",
      "Jeem                      total= 210 | train= 146 val=  32 test=  32\n",
      "Kaf                       total= 264 | train= 184 val=  40 test=  40\n",
      "Khah                      total= 250 | train= 174 val=  38 test=  38\n",
      "Laa                       total= 268 | train= 188 val=  40 test=  40\n",
      "Lam                       total= 260 | train= 182 val=  39 test=  39\n",
      "Meem                      total= 253 | train= 177 val=  38 test=  38\n",
      "Noon                      total= 237 | train= 165 val=  36 test=  36\n",
      "Qaf                       total= 219 | train= 153 val=  33 test=  33\n",
      "Reh                       total= 227 | train= 159 val=  34 test=  34\n",
      "Sad                       total= 270 | train= 190 val=  40 test=  40\n",
      "Seen                      total= 266 | train= 186 val=  40 test=  40\n",
      "Sheen                     total= 278 | train= 194 val=  42 test=  42\n",
      "Tah                       total= 226 | train= 158 val=  34 test=  34\n",
      "Teh                       total= 311 | train= 217 val=  47 test=  47\n",
      "Teh_Marbuta               total= 257 | train= 179 val=  39 test=  39\n",
      "Thal                      total= 202 | train= 142 val=  30 test=  30\n",
      "Theh                      total= 305 | train= 213 val=  46 test=  46\n",
      "Waw                       total= 249 | train= 175 val=  37 test=  37\n",
      "Yeh                       total= 272 | train= 190 val=  41 test=  41\n",
      "Zah                       total= 232 | train= 162 val=  35 test=  35\n",
      "Zain                      total= 201 | train= 141 val=  30 test=  30\n",
      "\n",
      "Wrote: 5496 train, 1180 val, 1180 test â†’ /home/noushath/NSResearch/ASLR/splits\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json, random, os\n",
    "\n",
    "# --- Configure these two paths ---\n",
    "ROOT = Path(\"/home/noushath/NSResearch/ASLR/data/RGB ArSL dataset/\").resolve()\n",
    "OUTDIR = Path(\"/home/noushath/NSResearch/ASLR/splits/\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 42\n",
    "ALLOWED_EXT = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "def is_image_ok(path: Path) -> bool:\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im.verify()\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def split_per_class(files, seed=42):\n",
    "    random.Random(seed).shuffle(files)\n",
    "    n = len(files)\n",
    "    if n >= 7:\n",
    "        test = max(1, round(0.15 * n))\n",
    "        val  = max(1, round(0.15 * n))\n",
    "        train = n - test - val\n",
    "        if train < 1:\n",
    "            train, val, test = max(1, n-2), 1, 1\n",
    "    elif n == 6: train, val, test = 4, 1, 1\n",
    "    elif n == 5: train, val, test = 3, 1, 1\n",
    "    elif n == 4: train, val, test = 2, 1, 1\n",
    "    elif n == 3: train, val, test = 1, 1, 1\n",
    "    elif n == 2: train, val, test = 1, 0, 1\n",
    "    else:        train, val, test = 1, 0, 0\n",
    "    return files[:train], files[train:train+val], files[train+val:train+val+test]\n",
    "\n",
    "# 1) Scan dataset: expect 1 subfolder per class beneath ROOT\n",
    "class_to_files = defaultdict(list)\n",
    "for cls_dir in sorted([p for p in ROOT.iterdir() if p.is_dir()]):\n",
    "    cls = cls_dir.name\n",
    "    for p in cls_dir.rglob(\"*\"):\n",
    "        if p.suffix.lower() in ALLOWED_EXT and p.is_file():\n",
    "            if is_image_ok(p):\n",
    "                class_to_files[cls].append(p)\n",
    "            else:\n",
    "                print(f\"Skipped corrupt image: {p}\")\n",
    "\n",
    "classes = sorted(class_to_files.keys())\n",
    "print(f\"Found {len(classes)} classes under {ROOT}\")\n",
    "\n",
    "# 2) Split per class and collect rows\n",
    "train_rows, val_rows, test_rows = [], [], []\n",
    "for cls in classes:\n",
    "    files = sorted(class_to_files[cls])\n",
    "    tr, va, te = split_per_class(files, seed=SEED)\n",
    "    for p in tr:  train_rows.append({\"image_path\": str(p), \"label\": cls})\n",
    "    for p in va:  val_rows.append({\"image_path\": str(p), \"label\": cls})\n",
    "    for p in te:  test_rows.append({\"image_path\": str(p), \"label\": cls})\n",
    "    print(f\"{cls:25s} total={len(files):4d} | train={len(tr):4d} val={len(va):4d} test={len(te):4d}\")\n",
    "\n",
    "# 3) Write CSVs and classes.json\n",
    "df_tr, df_va, df_te = pd.DataFrame(train_rows), pd.DataFrame(val_rows), pd.DataFrame(test_rows)\n",
    "df_tr.to_csv(OUTDIR / \"train.csv\", index=False)\n",
    "df_va.to_csv(OUTDIR / \"val.csv\",   index=False)\n",
    "df_te.to_csv(OUTDIR / \"test.csv\",  index=False)\n",
    "\n",
    "with open(OUTDIR / \"classes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"classes\": classes}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nWrote: {len(df_tr)} train, {len(df_va)} val, {len(df_te)} test â†’ {OUTDIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba2635-beea-4a60-9791-5584a2a0d371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(aslr)",
   "language": "python",
   "name": "aslr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
